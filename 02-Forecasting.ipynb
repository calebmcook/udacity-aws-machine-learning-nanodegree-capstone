{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad24fb35",
   "metadata": {},
   "source": [
    "# AWS Machine Learning Nandoegree Capstone Project\n",
    "# Forecasting with Amazon Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96e082",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7a5ca",
   "metadata": {},
   "source": [
    "\n",
    "### References\n",
    "Note! These steps were taken from the below reference Forecast walkthrough: \n",
    "https://github.com/aws-samples/amazon-forecast-samples/blob/main/notebooks/basic/Getting_Started/Amazon_Forecast_Quick_Start_Guide.ipynb\n",
    "https://github.com/aws-samples/amazon-forecast-samples/blob/main/notebooks/common/util/fcst_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b668fe",
   "metadata": {},
   "source": [
    "### Setup Notebook Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0a2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr setup\n",
    "\n",
    "!pip install pandas s3fs matplotlib ipywidgets\n",
    "!pip install boto3 --upgrade\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20939c6e",
   "metadata": {},
   "source": [
    "### Setup Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b7938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob \n",
    "#sys.path.insert( 0, os.path.abspath(\"../../common\") )\n",
    "\n",
    "import json\n",
    "from util import * #.fcst_utils import *\n",
    "import boto3\n",
    "import s3fs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b81f99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close(\"all\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deb718e",
   "metadata": {},
   "source": [
    "### Setup IAM Role used by Amazon Forecast to access your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c5c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#role was manually setup in AWS console, with AmazonS3FullAccess\n",
    "role_arn = 'arn:aws:iam::054619787751:role/my-forecast-role'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4acf0a7",
   "metadata": {},
   "source": [
    "### Create an instance of AWS SDK client for Amazon Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fdf845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-east-1'\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast')\n",
    "forecastquery = session.client(service_name='forecastquery')\n",
    "\n",
    "# Checking to make sure we can communicate with Amazon Forecast\n",
    "assert forecast.list_predictors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad529f",
   "metadata": {},
   "source": [
    "## Step 1: Import your data. <a class=\"anchor\" id=\"import\"></a>\n",
    "\n",
    "In this step, we will create a **Dataset** and **Import** the Taiwan stock dataset from S3 to Amazon Forecast. To train a Predictor we will need a **DatasetGroup** that groups the input **Datasets**. So, we will end this step by creating a **DatasetGroup** with the imported **Dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b38d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.Session().resource('s3')\n",
    "bucket_name = \"forecast-exp-1111\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25f1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[]\n",
    "files = glob.glob(os.path.join(os.getcwd(), \"forecast_import\", \"*\"))\n",
    "for file in files:\n",
    "    keys.append(r\"forecast_import/\"+os.path.split(file)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b7a322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forecast_import/target_wl.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d725e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done, the dataset is uploaded to S3 at s3://forecast-exp-1111/forecast_import/target_wl.parquet.\n"
     ]
    }
   ],
   "source": [
    "for key in keys:\n",
    "    s3.Bucket(bucket_name).Object(key).upload_file(key)\n",
    "    ts_s3_path = f\"s3://{bucket_name}/{key}\"\n",
    "\n",
    "print(f\"\\nDone, the dataset is uploaded to S3 at {ts_s3_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab654d3b",
   "metadata": {},
   "source": [
    "#### Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686db7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "DATASET_FREQUENCY = \"D\" # H for hourly.\n",
    "TS_DATASET_NAME = \"WATCHLIST_TS\"\n",
    "TS_SCHEMA = {\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      \n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"integer\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='TARGET_TIME_SERIES',\n",
    "                                                  DatasetName=TS_DATASET_NAME,\n",
    "                                                  DataFrequency=DATASET_FREQUENCY,\n",
    "                                                  Schema=TS_SCHEMA)\n",
    "\n",
    "ts_dataset_arn = create_dataset_response['DatasetArn']\n",
    "describe_dataset_response = forecast.describe_dataset(DatasetArn=ts_dataset_arn)\n",
    "\n",
    "print(f\"The Dataset with ARN {ts_dataset_arn} is now {describe_dataset_response['Status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cf9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn from error message when running above cell after already created\n",
    "ts_dataset_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset/WATCHLIST_TS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f3174",
   "metadata": {},
   "source": [
    "#### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c409a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Dataset Import Job with ARN arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS/PREFUNDING_TTS_IMPORT to become ACTIVE. This process could take 5-10 minutes.\n",
      "\n",
      "Current Status:\n",
      "CREATE_PENDING .\n",
      "CREATE_IN_PROGRESS ............................................................"
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "TS_IMPORT_JOB_NAME = \"PREFUNDING_TTS_IMPORT\"\n",
    "TIMEZONE = \"EST\"\n",
    "\n",
    "ts_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=TS_IMPORT_JOB_NAME,\n",
    "                                       DatasetArn=ts_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": ts_s3_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         } \n",
    "                                       },\n",
    "                                       Format=\"PARQUET\",\n",
    "                                       TimestampFormat=TIMESTAMP_FORMAT,\n",
    "                                       TimeZone = TIMEZONE)\n",
    "\n",
    "ts_dataset_import_job_arn = ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "\n",
    "print(f\"Waiting for Dataset Import Job with ARN {ts_dataset_import_job_arn} to become ACTIVE. This process could take 5-10 minutes.\\n\\nCurrent Status:\")\n",
    "\n",
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn))\n",
    "\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "print(f\"\\n\\nThe Dataset Import Job with ARN {ts_dataset_import_job_arn} is now {describe_dataset_import_job_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0197b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "# target dataset (watchlist) imported at:\n",
    "ts_dataset_import_job_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS/PREFUNDING_TTS_IMPORT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558794b",
   "metadata": {},
   "source": [
    "#### Creating a DatasetGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a27bf387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DatasetGroup with ARN arn:aws:forecast:us-east-1:054619787751:dataset-group/TAIWAN_PREFUNDING is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "DATASET_GROUP_NAME = \"TAIWAN_PREFUNDING\"\n",
    "DATASET_ARNS = [ts_dataset_arn]\n",
    "\n",
    "create_dataset_group_response = \\\n",
    "    forecast.create_dataset_group(Domain=\"CUSTOM\",\n",
    "                                  DatasetGroupName=DATASET_GROUP_NAME,\n",
    "                                  DatasetArns=DATASET_ARNS)\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "describe_dataset_group_response = forecast.describe_dataset_group(DatasetGroupArn=dataset_group_arn)\n",
    "\n",
    "print(f\"The DatasetGroup with ARN {dataset_group_arn} is now {describe_dataset_group_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f5d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "dataset_group_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset-group/TAIWAN_PREFUNDING'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d496a",
   "metadata": {},
   "source": [
    "## Step 2: Train a predictor - Experiment 01 <a class=\"anchor\" id=\"predictor\"></a>\n",
    "\n",
    "In this step, we will create a **Predictor** using the **DatasetGroup** that was created above. After creating the predictor, we will review the accuracy obtained through the backtesting process to get a quantitative understanding of the performance of the predictor.\n",
    "\n",
    "This will be the baseline predictor and experiment which we will expand on later with related datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16869314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Predictor with ARN arn:aws:forecast:us-east-1:054619787751:predictor/PREFUNDING_PREDICTOR_01_01GKW0Q4KG85PR41MRZXVXR7F5 to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE.\n",
      "\n",
      "Current Status:\n",
      "CREATE_PENDING ..\n",
      "CREATE_IN_PROGRESS ................."
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "PREDICTOR_NAME = \"PREFUNDING_PREDICTOR_01\"\n",
    "FORECAST_HORIZON = 1\n",
    "FORECAST_FREQUENCY = \"D\"\n",
    "#HOLIDAY_DATASET = [{\n",
    "#        'Name': 'holiday',\n",
    "#        'Configuration': {\n",
    "#        'CountryCode': ['TW']\n",
    "#    }\n",
    "#}]\n",
    "\n",
    "create_auto_predictor_response = \\\n",
    "    forecast.create_auto_predictor(PredictorName = PREDICTOR_NAME,\n",
    "                                   ForecastHorizon = FORECAST_HORIZON,\n",
    "                                   ForecastFrequency = FORECAST_FREQUENCY,\n",
    "                                   DataConfig = {\n",
    "                                       'DatasetGroupArn': dataset_group_arn\n",
    "                                       #,'AdditionalDatasets': HOLIDAY_DATASET\n",
    "                                        },\n",
    "                                   ExplainPredictor = True)\n",
    "\n",
    "predictor_arn = create_auto_predictor_response['PredictorArn']\n",
    "print(f\"Waiting for Predictor with ARN {predictor_arn} to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE.\\n\\nCurrent Status:\")\n",
    "\n",
    "status = util.wait(lambda: forecast.describe_auto_predictor(PredictorArn=predictor_arn))\n",
    "\n",
    "describe_auto_predictor_response = forecast.describe_auto_predictor(PredictorArn=predictor_arn)\n",
    "print(f\"\\n\\nThe Predictor with ARN {predictor_arn} is now {describe_auto_predictor_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e135294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "predictor_arn = 'arn:aws:forecast:us-east-1:054619787751:predictor/PREFUNDING_PREDICTOR_01_01GKW0Q4KG85PR41MRZXVXR7F5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a30dc",
   "metadata": {},
   "source": [
    "#### Review accuracy metrics\n",
    "\n",
    "* **Weighted Quantile Loss (wQL)** metric measures the accuracy of a model at a specified quantile. It is particularly useful when there are different costs for underpredicting and overpredicting.\n",
    "\n",
    "* **Root Mean Square Error (RMSE)** uses the squared value of the residuals, which amplifies the impact of outliers. In use cases where only a few large mispredictions can be very costly, the RMSE is the more relevant metric.\n",
    "\n",
    "* **Weighted Absolute Percentage Error (WAPE)** is more robust to outliers than Root Mean Square Error (RMSE) because it uses the absolute error instead of the squared error.\n",
    "\n",
    "* **Mean Absolute Percentage Error (MAPE)** is useful for cases where values differ significantly between time points and outliers have a significant impact.\n",
    "\n",
    "* **Mean Absolute Scaled Error (MASE)** is ideal for datasets that are cyclical in nature or have seasonal properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fb08aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Quantile Loss (wQL): [\n",
      "  {\n",
      "    \"Quantile\": 0.9,\n",
      "    \"LossValue\": 0.13846153846153844\n",
      "  },\n",
      "  {\n",
      "    \"Quantile\": 0.5,\n",
      "    \"LossValue\": 0.38461538461538464\n",
      "  },\n",
      "  {\n",
      "    \"Quantile\": 0.1,\n",
      "    \"LossValue\": 0.10769230769230768\n",
      "  }\n",
      "]\n",
      "Root Mean Square Error (RMSE): 0.38682272190477407\n",
      "Weighted Absolute Percentage Error (WAPE): 0.4653846153846153\n",
      "Mean Absolute Percentage Error (MAPE): 0.051818181818181826\n",
      "Mean Absolute Scaled Error (MASE): 1e-130\n"
     ]
    }
   ],
   "source": [
    "get_accuracy_metrics_response = forecast.get_accuracy_metrics(PredictorArn=predictor_arn)\n",
    "wql = get_accuracy_metrics_response['PredictorEvaluationResults'][0]['TestWindows'][0]['Metrics']['WeightedQuantileLosses']\n",
    "accuracy_scores = get_accuracy_metrics_response['PredictorEvaluationResults'][0]['TestWindows'][0]['Metrics']['ErrorMetrics'][0]\n",
    "\n",
    "print(f\"Weighted Quantile Loss (wQL): {json.dumps(wql, indent=2)}\")\n",
    "\n",
    "print(f\"Root Mean Square Error (RMSE): {accuracy_scores['RMSE']}\")\n",
    "\n",
    "print(f\"Weighted Absolute Percentage Error (WAPE): {accuracy_scores['WAPE']}\")\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {accuracy_scores['MAPE']}\")\n",
    "\n",
    "print(f\"Mean Absolute Scaled Error (MASE): {accuracy_scores['MASE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b23ed",
   "metadata": {},
   "source": [
    "#### Reviewing forecast\n",
    "I generated a forecast using the AWS console but noticed that the full universe of stocks wasn't generated by the forecast. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f80a7f98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://forecast-exp-1111/my_forecast_exp01/_SUCCESS to exp_01/forecast_01/_SUCCESS\n",
      "download: s3://forecast-exp-1111/my_forecast_exp01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part1.csv to exp_01/forecast_01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part1.csv\n",
      "download: s3://forecast-exp-1111/my_forecast_exp01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part0.csv to exp_01/forecast_01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part0.csv\n",
      "download: s3://forecast-exp-1111/my_forecast_exp01/_CHECK to exp_01/forecast_01/_CHECK\n",
      "download: s3://forecast-exp-1111/my_forecast_exp01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part3.csv to exp_01/forecast_01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part3.csv\n",
      "download: s3://forecast-exp-1111/my_forecast_exp01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part2.csv to exp_01/forecast_01/my_forecast_exp1_01_export_2022-12-10T22-22-10Z_part2.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://forecast-exp-1111/my_forecast_exp01/ ./exp_01/forecast_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "654efaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(f) for f in glob.glob(os.path.join(os.getcwd(),\"exp_01\",\"forecast_01\",\"*.csv\"))]\n",
    "forecasts_01 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8abb879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>p50</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1213</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1418</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1472</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1512</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1538</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2321</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2364</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2443</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2841</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3018</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3043</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3229</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3383</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3494</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3536</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4414</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6225</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6289</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8101</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9110</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9928</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                  date  p50  p90  p95\n",
       "3     1213  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "2     1418  2022-11-01T00:00:00Z  0.0  1.0  1.0\n",
       "1     1472  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "5     1512  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "0     1538  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "1     2025  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "2     2321  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "0     2364  2022-11-01T00:00:00Z  0.0  1.0  1.0\n",
       "2     2443  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "5     2841  2022-11-01T00:00:00Z  0.0  1.0  1.0\n",
       "4     3018  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "0     3043  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "3     3229  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "4     3383  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "0     3494  2022-11-01T00:00:00Z  0.0  1.0  1.0\n",
       "3     3536  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "1     4414  2022-11-01T00:00:00Z  0.0  1.0  1.0\n",
       "4     6225  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "2     6289  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "4     8101  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "1     9110  2022-11-01T00:00:00Z  1.0  1.0  1.0\n",
       "3     9928  2022-11-01T00:00:00Z  1.0  1.0  1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_01.sort_values('item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7731e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download backtest exports\n",
    "#!aws s3 sync s3://forecast-exp-1111/backtest_exports/ ./backtest_exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1aadcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_metric_values_files = glob.glob(\n",
    "#                                    os.path.join(os.getcwd(),\n",
    "#                                                 'backtest_exports', \n",
    "#                                                 'accuracy-metrics-values',\n",
    "#                                                 '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1425cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_metric_values_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "085cdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_metric_values = [pd.read_csv(f,sep=',') for f in accuracy_metric_values_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af65d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_01 = pd.concat(accuracy_metric_values, axis=0).sort_values(by=['item_id','backtestwindow_end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87217eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_01[acc_01['backtest_window']=='Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c36d3a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "msci_tw = ['2330',\n",
    "'2317',\n",
    "'2454',\n",
    "'2308',\n",
    "'2303',\n",
    "'2881',\n",
    "'2412',\n",
    "'2891',\n",
    "'1301',\n",
    "'2882',\n",
    "'1303',\n",
    "'2886',\n",
    "'2002',\n",
    "'3711',\n",
    "'1216',\n",
    "'2884',\n",
    "'5871',\n",
    "'2892',\n",
    "'5880',\n",
    "'1326',\n",
    "'2885',\n",
    "'3008',\n",
    "'1101',\n",
    "'2880',\n",
    "'2883',\n",
    "'2382',\n",
    "'2357',\n",
    "'3037',\n",
    "'2207',\n",
    "'5876',\n",
    "'2890',\n",
    "'3034',\n",
    "'2327',\n",
    "'3045',\n",
    "'2887',\n",
    "'2603',\n",
    "'2912',\n",
    "'6415',\n",
    "'8069',\n",
    "'2395',\n",
    "'2379',\n",
    "'1590',\n",
    "'2301',\n",
    "'4938',\n",
    "'2345',\n",
    "'1605',\n",
    "'2888',\n",
    "'6409',\n",
    "'2474',\n",
    "'2609',\n",
    "'3481',\n",
    "'4904',\n",
    "'1402',\n",
    "'6446',\n",
    "'2409',\n",
    "'6488',\n",
    "'6770',\n",
    "'3529',\n",
    "'1102',\n",
    "'6505',\n",
    "'1476',\n",
    "'2324',\n",
    "'9910',\n",
    "'2801',\n",
    "'2377',\n",
    "'2347',\n",
    "'6669',\n",
    "'2834',\n",
    "'9945',\n",
    "'3702',\n",
    "'4958',\n",
    "'5347',\n",
    "'9904',\n",
    "'2618',\n",
    "'9921',\n",
    "'2353',\n",
    "'2408',\n",
    "'8046',\n",
    "'4966',\n",
    "'2105',\n",
    "'2344',\n",
    "'2356',\n",
    "'2610',\n",
    "'2633',\n",
    "'3105',\n",
    "'2615',\n",
    "'8464',\n",
    "'8454',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5228c5",
   "metadata": {},
   "source": [
    "## Experiment 01.2 <a class=\"anchor\" id=\"predictor\"></a>\n",
    "### Training a new predictor on updated watchlist data (correctly handling nulls). Update forecast horizon to 5 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7aa88",
   "metadata": {},
   "source": [
    "#### Import updated data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26b37d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: forecast_import/target_wl2.parquet to s3://forecast-exp-1111/forecast_import/target_wl2.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync ./forecast_import/ s3://forecast-exp-1111/forecast_import/ #--dryrun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbd8c8",
   "metadata": {},
   "source": [
    "#### Creating new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db3ab9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset with ARN arn:aws:forecast:us-east-1:054619787751:dataset/WATCHLIST_TS_2 is now ACTIVE\n"
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "DATASET_FREQUENCY = \"D\" # H for hourly.\n",
    "TS_DATASET_NAME = \"WATCHLIST_TS_2\"\n",
    "TS_SCHEMA = {\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      \n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"integer\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='TARGET_TIME_SERIES',\n",
    "                                                  DatasetName=TS_DATASET_NAME,\n",
    "                                                  DataFrequency=DATASET_FREQUENCY,\n",
    "                                                  Schema=TS_SCHEMA)\n",
    "\n",
    "ts_dataset_arn = create_dataset_response['DatasetArn']\n",
    "describe_dataset_response = forecast.describe_dataset(DatasetArn=ts_dataset_arn)\n",
    "\n",
    "print(f\"The Dataset with ARN {ts_dataset_arn} is now {describe_dataset_response['Status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d66b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "ts2_dataset_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset/WATCHLIST_TS_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe3f94",
   "metadata": {},
   "source": [
    "#### Importing new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ff746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2_s3_path = 's3://forecast-exp-1111/forecast_import/target_wl2.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66ca0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Dataset Import Job with ARN arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS_2/PREFUNDING_TTS_IMPORT_02 to become ACTIVE. This process could take 5-10 minutes.\n",
      "\n",
      "Current Status:\n",
      "CREATE_PENDING .\n",
      "CREATE_IN_PROGRESS .........\n",
      "ACTIVE \n",
      "\n",
      "\n",
      "The Dataset Import Job with ARN arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS_2/PREFUNDING_TTS_IMPORT_02 is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "TS_IMPORT_JOB_NAME = \"PREFUNDING_TTS_IMPORT_02\"\n",
    "TIMEZONE = \"EST\"\n",
    "\n",
    "ts_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=TS_IMPORT_JOB_NAME,\n",
    "                                       DatasetArn=ts2_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": ts2_s3_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         } \n",
    "                                       },\n",
    "                                       Format=\"PARQUET\",\n",
    "                                       TimestampFormat=TIMESTAMP_FORMAT,\n",
    "                                       TimeZone = TIMEZONE)\n",
    "\n",
    "ts_dataset_import_job_arn = ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "\n",
    "print(f\"Waiting for Dataset Import Job with ARN {ts_dataset_import_job_arn} to become ACTIVE. This process could take 5-10 minutes.\\n\\nCurrent Status:\")\n",
    "\n",
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn))\n",
    "\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "print(f\"\\n\\nThe Dataset Import Job with ARN {ts_dataset_import_job_arn} is now {describe_dataset_import_job_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb9594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "dataset_group_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS_2/PREFUNDING_TTS_IMPORT_02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcc8b5",
   "metadata": {},
   "source": [
    "#### Creating a DatasetGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d4808d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DatasetGroup with ARN arn:aws:forecast:us-east-1:054619787751:dataset-group/TAIWAN_PREFUNDING_01_02 is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "DATASET_GROUP_NAME = \"TAIWAN_PREFUNDING_01_02\"\n",
    "DATASET_ARNS = [ts2_dataset_arn]\n",
    "\n",
    "create_dataset_group_response = \\\n",
    "    forecast.create_dataset_group(Domain=\"CUSTOM\",\n",
    "                                  DatasetGroupName=DATASET_GROUP_NAME,\n",
    "                                  DatasetArns=DATASET_ARNS)\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "describe_dataset_group_response = forecast.describe_dataset_group(DatasetGroupArn=dataset_group_arn)\n",
    "\n",
    "print(f\"The DatasetGroup with ARN {dataset_group_arn} is now {describe_dataset_group_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2276299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "dataset_group_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset-group/TAIWAN_PREFUNDING_01_02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7cd06",
   "metadata": {},
   "source": [
    "#### Train a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9156562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Predictor with ARN arn:aws:forecast:us-east-1:054619787751:predictor/PREFUNDING_PREDICTOR_01_02_01GM3KN277EYERQD7VNAMN254K to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE.\n",
      "\n",
      "Current Status:\n"
     ]
    }
   ],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "PREDICTOR_NAME = \"PREFUNDING_PREDICTOR_01_02\"\n",
    "FORECAST_HORIZON = 5\n",
    "FORECAST_FREQUENCY = \"D\"\n",
    "#HOLIDAY_DATASET = [{\n",
    "#        'Name': 'holiday',\n",
    "#        'Configuration': {\n",
    "#        'CountryCode': ['TW']\n",
    "#    }\n",
    "#}]\n",
    "\n",
    "create_auto_predictor_response = \\\n",
    "    forecast.create_auto_predictor(PredictorName = PREDICTOR_NAME,\n",
    "                                   ForecastHorizon = FORECAST_HORIZON,\n",
    "                                   ForecastFrequency = FORECAST_FREQUENCY,\n",
    "                                   DataConfig = {\n",
    "                                       'DatasetGroupArn': dataset_group_arn\n",
    "                                       #,'AdditionalDatasets': HOLIDAY_DATASET\n",
    "                                        },\n",
    "                                   ExplainPredictor = True)\n",
    "\n",
    "predictor_arn = create_auto_predictor_response['PredictorArn']\n",
    "print(f\"Waiting for Predictor with ARN {predictor_arn} to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE.\")\n",
    "\n",
    "#status = util.wait(lambda: forecast.describe_auto_predictor(PredictorArn=predictor_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293f08d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Predictor with ARN arn:aws:forecast:us-east-1:054619787751:predictor/PREFUNDING_PREDICTOR_01_02_01GM3KN277EYERQD7VNAMN254K is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "#Get current status of predictor\n",
    "describe_auto_predictor_response = forecast.describe_auto_predictor(PredictorArn=predictor_arn)\n",
    "print(f\"\\n\\nThe Predictor with ARN {predictor_arn} is now {describe_auto_predictor_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1b7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "predictor_arn = 'arn:aws:forecast:us-east-1:054619787751:predictor/PREFUNDING_PREDICTOR_01_02_01GM3KN277EYERQD7VNAMN254K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5941f82",
   "metadata": {},
   "source": [
    "#### Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3aaad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Quantile Loss (wQL): [\n",
      "  {\n",
      "    \"Quantile\": 0.9,\n",
      "    \"LossValue\": 0.033315385946153776\n",
      "  },\n",
      "  {\n",
      "    \"Quantile\": 0.5,\n",
      "    \"LossValue\": 0.024813485476922994\n",
      "  },\n",
      "  {\n",
      "    \"Quantile\": 0.1,\n",
      "    \"LossValue\": 0.038043852469230935\n",
      "  }\n",
      "]\n",
      "Root Mean Square Error (RMSE): 0.0069419847508758\n",
      "Weighted Absolute Percentage Error (WAPE): 0.06988694954358965\n",
      "Mean Absolute Percentage Error (MAPE): 0.00024693699124686194\n",
      "Mean Absolute Scaled Error (MASE): 0.0008089736696903767\n"
     ]
    }
   ],
   "source": [
    "get_accuracy_metrics_response = forecast.get_accuracy_metrics(PredictorArn=predictor_arn)\n",
    "wql = get_accuracy_metrics_response['PredictorEvaluationResults'][0]['TestWindows'][0]['Metrics']['WeightedQuantileLosses']\n",
    "accuracy_scores = get_accuracy_metrics_response['PredictorEvaluationResults'][0]['TestWindows'][0]['Metrics']['ErrorMetrics'][0]\n",
    "\n",
    "print(f\"Weighted Quantile Loss (wQL): {json.dumps(wql, indent=2)}\")\n",
    "\n",
    "print(f\"Root Mean Square Error (RMSE): {accuracy_scores['RMSE']}\")\n",
    "\n",
    "print(f\"Weighted Absolute Percentage Error (WAPE): {accuracy_scores['WAPE']}\")\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {accuracy_scores['MAPE']}\")\n",
    "\n",
    "print(f\"Mean Absolute Scaled Error (MASE): {accuracy_scores['MASE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5a08e",
   "metadata": {},
   "source": [
    "#### Generate forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91da1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Forecast with ARN arn:aws:forecast:us-east-1:054619787751:forecast/MY_FORECAST_EXP_01_02 to become ACTIVE. Depending on data size and predictor settings，it can take several hours to be ACTIVE.\n",
      "\n",
      "Current Status:\n"
     ]
    }
   ],
   "source": [
    "FORECAST_NAME = \"MY_FORECAST_EXP_01_02\"\n",
    "\n",
    "create_forecast_response = \\\n",
    "    forecast.create_forecast(ForecastName=FORECAST_NAME,\n",
    "                             PredictorArn=predictor_arn)\n",
    "\n",
    "forecast_arn = create_forecast_response['ForecastArn']\n",
    "print(f\"Waiting for Forecast with ARN {forecast_arn} to become ACTIVE. Depending on data size and predictor settings，it can take several hours to be ACTIVE.\\n\\nCurrent Status:\")\n",
    "\n",
    "#status = util.wait(lambda: forecast.describe_forecast(ForecastArn=forecast_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e68e6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Forecast with ARN arn:aws:forecast:us-east-1:054619787751:forecast/MY_FORECAST_EXP_01_02 is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "describe_forecast_response = forecast.describe_forecast(ForecastArn=forecast_arn)\n",
    "print(f\"\\n\\nThe Forecast with ARN {forecast_arn} is now {describe_forecast_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13461b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn original cell execution above\n",
    "predictor_arn = 'arn:aws:forecast:us-east-1:054619787751:forecast/MY_FORECAST_EXP_01_02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create Forecast export job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "828fb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = forecast.create_forecast_export_job(\n",
    "    ForecastExportJobName='my_forecast_exp_01_02',\n",
    "    ForecastArn=forecast_arn,\n",
    "    Destination={\n",
    "        'S3Config': {\n",
    "            'Path': 's3://forecast-exp-1111/my_forecast_exp_01_02/',\n",
    "            'RoleArn': role_arn\n",
    "            #'KMSKeyArn': 'string'\n",
    "        }\n",
    "    }\n",
    "    #Format='CSV'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1e3d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 sync s3://forecast-exp-1111/my_forecast_exp_01_02 ./exp_01_02/forecast_01_02 #--dryrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5444a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(f) for f in glob.glob(os.path.join(os.getcwd(),\"exp_01_02\",\"forecast_01_02\",\"*.csv\"))]\n",
    "forecasts_01_02 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a944446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1195"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_01_02['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7756d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>p10</th>\n",
       "      <th>p50</th>\n",
       "      <th>p90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1235</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1235</td>\n",
       "      <td>2022-11-02T00:00:00Z</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235</td>\n",
       "      <td>2022-11-03T00:00:00Z</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1235</td>\n",
       "      <td>2022-11-04T00:00:00Z</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1235</td>\n",
       "      <td>2022-11-05T00:00:00Z</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9136</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9136</td>\n",
       "      <td>2022-11-02T00:00:00Z</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9136</td>\n",
       "      <td>2022-11-03T00:00:00Z</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9136</td>\n",
       "      <td>2022-11-04T00:00:00Z</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9136</td>\n",
       "      <td>2022-11-05T00:00:00Z</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5975 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                  date       p10       p50       p90\n",
       "0     1235  2022-11-01T00:00:00Z -0.000050 -0.000024  0.000014\n",
       "1     1235  2022-11-02T00:00:00Z -0.000053 -0.000022  0.000009\n",
       "2     1235  2022-11-03T00:00:00Z -0.000044 -0.000021  0.000007\n",
       "3     1235  2022-11-04T00:00:00Z -0.000050 -0.000019  0.000022\n",
       "4     1235  2022-11-05T00:00:00Z -0.000045 -0.000017  0.000018\n",
       "..     ...                   ...       ...       ...       ...\n",
       "30    9136  2022-11-01T00:00:00Z -0.000044 -0.000020  0.000012\n",
       "31    9136  2022-11-02T00:00:00Z -0.000053 -0.000024  0.000002\n",
       "32    9136  2022-11-03T00:00:00Z -0.000044 -0.000019  0.000024\n",
       "33    9136  2022-11-04T00:00:00Z -0.000048 -0.000020  0.000014\n",
       "34    9136  2022-11-05T00:00:00Z -0.000052 -0.000017  0.000014\n",
       "\n",
       "[5975 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_01_02#['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b906ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_1101 = ['1213','1472','1512','1538','2025','2321','2443','3018','3043','3536','6225','8101','9110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3c176f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>p10</th>\n",
       "      <th>p50</th>\n",
       "      <th>p90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1213</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>1.001231</td>\n",
       "      <td>1.014586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1213</td>\n",
       "      <td>2022-11-02T00:00:00Z</td>\n",
       "      <td>0.986222</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>1.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1213</td>\n",
       "      <td>2022-11-03T00:00:00Z</td>\n",
       "      <td>0.988338</td>\n",
       "      <td>0.997103</td>\n",
       "      <td>1.017501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1213</td>\n",
       "      <td>2022-11-04T00:00:00Z</td>\n",
       "      <td>0.922382</td>\n",
       "      <td>0.977046</td>\n",
       "      <td>1.015014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1213</td>\n",
       "      <td>2022-11-05T00:00:00Z</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.011387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2443</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.989733</td>\n",
       "      <td>1.000846</td>\n",
       "      <td>1.016798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2443</td>\n",
       "      <td>2022-11-02T00:00:00Z</td>\n",
       "      <td>0.985751</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>1.012005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2443</td>\n",
       "      <td>2022-11-03T00:00:00Z</td>\n",
       "      <td>0.987436</td>\n",
       "      <td>0.996902</td>\n",
       "      <td>1.007511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2443</td>\n",
       "      <td>2022-11-04T00:00:00Z</td>\n",
       "      <td>0.928538</td>\n",
       "      <td>0.980124</td>\n",
       "      <td>1.031793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2443</td>\n",
       "      <td>2022-11-05T00:00:00Z</td>\n",
       "      <td>-0.000949</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.010979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3018</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.992192</td>\n",
       "      <td>1.001669</td>\n",
       "      <td>1.016343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3018</td>\n",
       "      <td>2022-11-02T00:00:00Z</td>\n",
       "      <td>0.984520</td>\n",
       "      <td>0.997037</td>\n",
       "      <td>1.006006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3018</td>\n",
       "      <td>2022-11-03T00:00:00Z</td>\n",
       "      <td>0.985697</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>1.012007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3018</td>\n",
       "      <td>2022-11-04T00:00:00Z</td>\n",
       "      <td>0.930763</td>\n",
       "      <td>0.975058</td>\n",
       "      <td>1.017591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3018</td>\n",
       "      <td>2022-11-05T00:00:00Z</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.010892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6225</td>\n",
       "      <td>2022-11-01T00:00:00Z</td>\n",
       "      <td>0.993162</td>\n",
       "      <td>1.002569</td>\n",
       "      <td>1.012899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6225</td>\n",
       "      <td>2022-11-02T00:00:00Z</td>\n",
       "      <td>0.988835</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>1.010648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6225</td>\n",
       "      <td>2022-11-03T00:00:00Z</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>1.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6225</td>\n",
       "      <td>2022-11-04T00:00:00Z</td>\n",
       "      <td>0.941486</td>\n",
       "      <td>0.973283</td>\n",
       "      <td>1.022647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6225</td>\n",
       "      <td>2022-11-05T00:00:00Z</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.011074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                  date       p10       p50       p90\n",
       "15    1213  2022-11-01T00:00:00Z  0.988473  1.001231  1.014586\n",
       "16    1213  2022-11-02T00:00:00Z  0.986222  0.998600  1.009422\n",
       "17    1213  2022-11-03T00:00:00Z  0.988338  0.997103  1.017501\n",
       "18    1213  2022-11-04T00:00:00Z  0.922382  0.977046  1.015014\n",
       "19    1213  2022-11-05T00:00:00Z -0.000159  0.005434  0.011387\n",
       "25    2443  2022-11-01T00:00:00Z  0.989733  1.000846  1.016798\n",
       "26    2443  2022-11-02T00:00:00Z  0.985751  0.999528  1.012005\n",
       "27    2443  2022-11-03T00:00:00Z  0.987436  0.996902  1.007511\n",
       "28    2443  2022-11-04T00:00:00Z  0.928538  0.980124  1.031793\n",
       "29    2443  2022-11-05T00:00:00Z -0.000949  0.006161  0.010979\n",
       "25    3018  2022-11-01T00:00:00Z  0.992192  1.001669  1.016343\n",
       "26    3018  2022-11-02T00:00:00Z  0.984520  0.997037  1.006006\n",
       "27    3018  2022-11-03T00:00:00Z  0.985697  0.998131  1.012007\n",
       "28    3018  2022-11-04T00:00:00Z  0.930763  0.975058  1.017591\n",
       "29    3018  2022-11-05T00:00:00Z -0.000420  0.005498  0.010892\n",
       "30    6225  2022-11-01T00:00:00Z  0.993162  1.002569  1.012899\n",
       "31    6225  2022-11-02T00:00:00Z  0.988835  0.999504  1.010648\n",
       "32    6225  2022-11-03T00:00:00Z  0.988166  0.998975  1.009758\n",
       "33    6225  2022-11-04T00:00:00Z  0.941486  0.973283  1.022647\n",
       "34    6225  2022-11-05T00:00:00Z  0.000745  0.006251  0.011074"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing the 5-day predictions for the 13 stocks that show up on the actual watchlist for 11/01/2022:\n",
    "forecasts_01_02[forecasts_01_02['item_id'].isin(actuals_1101)].sort_values(['item_id','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0880b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5783283",
   "metadata": {},
   "source": [
    "## Experiment 02 <a class=\"anchor\" id=\"predictor\"></a>\n",
    "### Incorporating related data into the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afc9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
