{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c51b93",
   "metadata": {},
   "source": [
    "# AWS Machine Learning Nandoegree Capstone Project\n",
    "# Forecasting with Amazon Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c54f49",
   "metadata": {},
   "source": [
    "## Note! These steps were taken from the below reference Forecast walkthrough: \n",
    "https://github.com/aws-samples/amazon-forecast-samples/blob/main/notebooks/basic/Getting_Started/Amazon_Forecast_Quick_Start_Guide.ipynb\n",
    "https://github.com/aws-samples/amazon-forecast-samples/blob/main/notebooks/common/util/fcst_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e8eec",
   "metadata": {},
   "source": [
    "#### Setup Notebook Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92eebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr setup\n",
    "\n",
    "!pip install pandas s3fs matplotlib ipywidgets\n",
    "!pip install boto3 --upgrade\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc18c9",
   "metadata": {},
   "source": [
    "#### Setup Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a3d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob \n",
    "#sys.path.insert( 0, os.path.abspath(\"../../common\") )\n",
    "\n",
    "import json\n",
    "from util.fcst_utils import *\n",
    "import boto3\n",
    "import s3fs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef398b97",
   "metadata": {},
   "source": [
    "#### Setup IAM Role used by Amazon Forecast to access your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4439e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#role was manually setup in AWS console, with AmazonS3FullAccess\n",
    "role_arn = 'arn:aws:iam::054619787751:role/my-forecast-role'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a8e30",
   "metadata": {},
   "source": [
    "#### Create an instance of AWS SDK client for Amazon Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5756f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-east-1'\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast')\n",
    "forecastquery = session.client(service_name='forecastquery')\n",
    "\n",
    "# Checking to make sure we can communicate with Amazon Forecast\n",
    "assert forecast.list_predictors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d4b93",
   "metadata": {},
   "source": [
    "## Step 1: Import your data. <a class=\"anchor\" id=\"import\"></a>\n",
    "\n",
    "In this step, we will create a **Dataset** and **Import** the Taiwan stock dataset from S3 to Amazon Forecast. To train a Predictor we will need a **DatasetGroup** that groups the input **Datasets**. So, we will end this step by creating a **DatasetGroup** with the imported **Dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b5be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.Session().resource('s3')\n",
    "bucket_name = \"forecast-exp-1111\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527d9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[]\n",
    "files = glob.glob(os.path.join(os.getcwd(), \"forecast_import\", \"*\"))\n",
    "for file in files:\n",
    "    keys.append(r\"forecast_import/\"+os.path.split(file)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f94f664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forecast_import/target_wl.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442e958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done, the dataset is uploaded to S3 at s3://forecast-exp-1111/forecast_import/target_wl.parquet.\n"
     ]
    }
   ],
   "source": [
    "for key in keys:\n",
    "    s3.Bucket(bucket_name).Object(key).upload_file(key)\n",
    "    ts_s3_path = f\"s3://{bucket_name}/{key}\"\n",
    "\n",
    "print(f\"\\nDone, the dataset is uploaded to S3 at {ts_s3_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa5b80",
   "metadata": {},
   "source": [
    "#### Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a76cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY NEED TO RUN THIS ONCE. SKIP TO NEXT CELL IF CREATED PREVIOUSLY.\n",
    "DATASET_FREQUENCY = \"D\" # H for hourly.\n",
    "TS_DATASET_NAME = \"WATCHLIST_TS\"\n",
    "TS_SCHEMA = {\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      \n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"integer\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='TARGET_TIME_SERIES',\n",
    "                                                  DatasetName=TS_DATASET_NAME,\n",
    "                                                  DataFrequency=DATASET_FREQUENCY,\n",
    "                                                  Schema=TS_SCHEMA)\n",
    "\n",
    "ts_dataset_arn = create_dataset_response['DatasetArn']\n",
    "describe_dataset_response = forecast.describe_dataset(DatasetArn=ts_dataset_arn)\n",
    "\n",
    "print(f\"The Dataset with ARN {ts_dataset_arn} is now {describe_dataset_response['Status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec82a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF YOU HAVE ALREADY RUN THE ABOVE CELL\n",
    "#Obtained arn from error message when running above cell after already created\n",
    "ts_dataset_arn = 'arn:aws:forecast:us-east-1:054619787751:dataset/WATCHLIST_TS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd037f",
   "metadata": {},
   "source": [
    "#### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Dataset Import Job with ARN arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS/PREFUNDING_TTS_IMPORT to become ACTIVE. This process could take 5-10 minutes.\n",
      "\n",
      "Current Status:\n",
      "CREATE_PENDING .\n",
      "CREATE_IN_PROGRESS .."
     ]
    }
   ],
   "source": [
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "TS_IMPORT_JOB_NAME = \"PREFUNDING_TTS_IMPORT\"\n",
    "TIMEZONE = \"EST\"\n",
    "\n",
    "ts_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=TS_IMPORT_JOB_NAME,\n",
    "                                       DatasetArn=ts_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": ts_s3_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         } \n",
    "                                       },\n",
    "                                       Format=\"PARQUET\",\n",
    "                                       TimestampFormat=TIMESTAMP_FORMAT,\n",
    "                                       TimeZone = TIMEZONE)\n",
    "\n",
    "ts_dataset_import_job_arn = ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "\n",
    "print(f\"Waiting for Dataset Import Job with ARN {ts_dataset_import_job_arn} to become ACTIVE. This process could take 5-10 minutes.\\n\\nCurrent Status:\")\n",
    "\n",
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn))\n",
    "\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "print(f\"\\n\\nThe Dataset Import Job with ARN {ts_dataset_import_job_arn} is now {describe_dataset_import_job_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755661d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target dataset (watchlist) imported at:\n",
    "# arn:aws:forecast:us-east-1:054619787751:dataset-import-job/WATCHLIST_TS/PREFUNDING_TTS_IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc532662",
   "metadata": {},
   "source": [
    "#### Creating a DatasetGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8b28c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DatasetGroup with ARN arn:aws:forecast:us-east-1:054619787751:dataset-group/TAIWAN_PREFUNDING is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "DATASET_GROUP_NAME = \"TAIWAN_PREFUNDING\"\n",
    "DATASET_ARNS = [ts_dataset_arn]\n",
    "\n",
    "create_dataset_group_response = \\\n",
    "    forecast.create_dataset_group(Domain=\"CUSTOM\",\n",
    "                                  DatasetGroupName=DATASET_GROUP_NAME,\n",
    "                                  DatasetArns=DATASET_ARNS)\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "describe_dataset_group_response = forecast.describe_dataset_group(DatasetGroupArn=dataset_group_arn)\n",
    "\n",
    "print(f\"The DatasetGroup with ARN {dataset_group_arn} is now {describe_dataset_group_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d5521",
   "metadata": {},
   "source": [
    "## Step 2: Train a predictor - Experiment 01 <a class=\"anchor\" id=\"predictor\"></a>\n",
    "\n",
    "In this step, we will create a **Predictor** using the **DatasetGroup** that was created above. After creating the predictor, we will review the accuracy obtained through the backtesting process to get a quantitative understanding of the performance of the predictor.\n",
    "\n",
    "This will be the baseline predictor and experiment which we will expand on later with related datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d01dc806",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundException",
     "evalue": "An error occurred (ResourceNotFoundException) when calling the CreateAutoPredictor operation: Datasets: [arn:aws:forecast:us-east-1:054619787751:dataset/WATCHLIST_TS] have never been successfully imported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16857/1282349591.py\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcreate_auto_predictor_response\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     forecast.create_auto_predictor(PredictorName = PREDICTOR_NAME,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                    \u001b[0mForecastHorizon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFORECAST_HORIZON\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                    \u001b[0mForecastFrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFORECAST_FREQUENCY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceNotFoundException\u001b[0m: An error occurred (ResourceNotFoundException) when calling the CreateAutoPredictor operation: Datasets: [arn:aws:forecast:us-east-1:054619787751:dataset/WATCHLIST_TS] have never been successfully imported."
     ]
    }
   ],
   "source": [
    "PREDICTOR_NAME = \"PREFUNDING_PREDICTOR_01\"\n",
    "FORECAST_HORIZON = 1\n",
    "FORECAST_FREQUENCY = \"D\"\n",
    "HOLIDAY_DATASET = [{\n",
    "        'Name': 'holiday',\n",
    "        'Configuration': {\n",
    "        'CountryCode': ['TW']\n",
    "    }\n",
    "}]\n",
    "\n",
    "create_auto_predictor_response = \\\n",
    "    forecast.create_auto_predictor(PredictorName = PREDICTOR_NAME,\n",
    "                                   ForecastHorizon = FORECAST_HORIZON,\n",
    "                                   ForecastFrequency = FORECAST_FREQUENCY,\n",
    "                                   DataConfig = {\n",
    "                                       'DatasetGroupArn': dataset_group_arn, \n",
    "                                       'AdditionalDatasets': HOLIDAY_DATASET\n",
    "                                    },\n",
    "                                   ExplainPredictor = True)\n",
    "\n",
    "predictor_arn = create_auto_predictor_response['PredictorArn']\n",
    "print(f\"Waiting for Predictor with ARN {predictor_arn} to become ACTIVE. Depending on data size and predictor setting，it can take several hours to be ACTIVE.\\n\\nCurrent Status:\")\n",
    "\n",
    "status = util.wait(lambda: forecast.describe_auto_predictor(PredictorArn=predictor_arn))\n",
    "\n",
    "describe_auto_predictor_response = forecast.describe_auto_predictor(PredictorArn=predictor_arn)\n",
    "print(f\"\\n\\nThe Predictor with ARN {predictor_arn} is now {describe_auto_predictor_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341cc62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
